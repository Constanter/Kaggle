{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n## **Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ**","metadata":{"id":"fQlDjKcWcb1I"}},{"cell_type":"markdown","source":"# Путешествие по Спрингфилду.\n\n\nСегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.\n\n\n\n ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)\n\n","metadata":{"id":"Xw7YkEefehWo"}},{"cell_type":"markdown","source":"### Установка зависимостей","metadata":{"id":"oG47vhLxKNln"}},{"cell_type":"code","source":"# we will verify that GPU is enabled for this notebook\n# following should print: CUDA is available!  Training on GPU ...\n# \n# if it prints otherwise, then you need to enable GPU: \n# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n\nimport torch\nimport numpy as np\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"id":"WWgcwKwCLBfr","outputId":"ee694cc5-62d0-4664-ea2a-0f359bea120a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"TTQXgo_oYDx8"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/gdrive/')","metadata":{"id":"xA3o2xC3MlMI","outputId":"43c45416-abfc-491e-ee1d-78b8ba959e20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ","metadata":{"id":"D2dg3IHMMo-s","outputId":"4f8c419a-b62a-4e54-e4bf-6a5a247b6ca5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q  /content/gdrive/MyDrive/journey-springfield.zip -d dataset","metadata":{"id":"Eql8-ma0zBHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\nimport torch\ntorch.cuda.is_available()","metadata":{"id":"GvWhlkiRMxih","outputId":"6442bec7-a2fc-49fd-89d7-59c5ad49ef9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс.","metadata":{"id":"BD_8gK6PmgXk"}},{"cell_type":"code","source":"import pickle\nimport numpy as np\nfrom skimage import io\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom torchvision import transforms\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nfrom matplotlib import colors, pyplot as plt\n%matplotlib inline\n\n# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n# мы будем игнорировать warnings\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\n","metadata":{"id":"naD6xsZzMxrC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# разные режимы датасета \nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE = 224\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\")","metadata":{"id":"WTdzMtgJP15N","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n","metadata":{"id":"HYFeKUzfy572"}},{"cell_type":"markdown","source":"Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. \n\nToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n$input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n\n\nСтоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) ","metadata":{"id":"8ecnkB2xK1aE"}},{"cell_type":"code","source":"class SimpsonsDataset(Dataset):\n    \"\"\"\n    Датасет с картинками, который паралельно подгружает их из папок\n    производит скалирование и превращение в торчевые тензоры\n    \"\"\"\n    def __init__(self, files, mode):\n        super().__init__()\n        # список файлов для загрузки\n        self.files = sorted(files)\n        # режим работы\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n     \n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n  \n    def __getitem__(self, index):\n        # для преобразования изображений в тензоры PyTorch и нормализации входа\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n        ])\n        data_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        #transforms.RandomGrayscale(p=0.1),\n        #transforms.RandomAffine(degrees = 20),\n        #transforms.RandomPerspective(),\n        #transforms.RandomErasing(),     \n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomHorizontalFlip(p=0.5),])\n        x = self.load_sample(self.files[index])\n        x = self._prepare_sample(x)\n        x = np.array(x / 255, dtype='float32')\n        if self.mode == 'train':\n          x = data_transforms(x)\n        else:\n          x = transform(x)\n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            label_id = self.label_encoder.transform([label])\n            y = label_id.item()\n            return x, y\n        \n    def _prepare_sample(self, image):\n        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n        return np.array(image)","metadata":{"id":"cj32U5iTQUe4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","metadata":{"id":"j_odtTEzcaWH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = Path('/content/dataset/train/simpsons_dataset')\nTEST_DIR = Path('/content/dataset/testset/testset')\n\ntrain_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))\ntrain_val_labels = [path.parent.name for path in train_val_files]","metadata":{"id":"yUhzOq1zRJil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nTRAIN_DIR = Path(r'../input/journey-springfield/train/simpsons_dataset')\nTEST_DIR = Path(r'../input/journey-springfield/testset/testset')\n\ntrain_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))\ntrain_val_labels = [path.parent.name for path in train_val_files]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_val_files = []\nd ={}\nfor i in train_val_labels:\n  if i in d:\n    d[i] += 1\n  else:\n    d[i] = 1\n\n\nfor i in d:\n  f_path = Path(f'../input/journey-springfield/train/simpsons_dataset/{i}')\n  train_val_files.extend(list(f_path.rglob('*.jpg'))* (2246//d[i]))\n\nlen(train_val_files)","metadata":{"id":"q4jemoAincaA","outputId":"257fb729-c767-44a7-8177-bfbe68385088","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"42 * 2246","metadata":{"id":"3zgYelHBNFLM","outputId":"62d40ada-a91d-49d6-ca58-a529c22061a3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.4, \\\n                                          stratify=train_val_labels,shuffle = True)","metadata":{"id":"TmPhhKKlRyCF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = SimpsonsDataset(val_files, mode='val')","metadata":{"id":"aAimOLjSQGTh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Давайте посмотрим на наших героев внутри датасета.","metadata":{"id":"PmKSdyv1b7PD"}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=4,figsize=(18, 18), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"id":"ltitWp3lXAZt","outputId":"a5ff6c72-29b5-4094-b097-57434b4eb26a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)","metadata":{"id":"GpN9lSi4QVGt"}},{"cell_type":"markdown","source":"### Построение нейросети\n\nЗапустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n\nДанная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n\n<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n\n*Описание слоев*:\n\n\n\n1. размерность входа: 3x224x224 \n2.размерности после слоя:  8x111x111\n3. 16x54x54\n4. 32x26x26\n5. 64x12x12\n6. выход: 96x5x5\n","metadata":{"id":"u6YcZk8vQR47"}},{"cell_type":"code","source":"","metadata":{"id":"50IFxRj_N6T9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Очень простая сеть\nclass SimpleCnn(nn.Module):\n  \n    def __init__(self, n_classes):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n        )\n        \n        self.out = nn.Linear(96 * 5 * 5, n_classes)\n  \n  \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n\n        x = x.view(x.size(0), -1)\n        logits = self.out(x)\n        return logits","metadata":{"id":"1PJcWAhuji-i","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        preds = torch.argmax(outputs, 1)\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc","metadata":{"id":"e2mk7MNtcUhJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in val_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","metadata":{"id":"w_CD9--hcUjs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, epochs, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        opt = torch.optim.AdamW(model.parameters())\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n            history.append((train_loss, train_acc, val_loss, val_acc))\n            \n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n            \n    return history","metadata":{"id":"NaxYIwB3cUmX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"id":"v6G7qbYqcUpL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nn_classes = len(np.unique(train_val_labels))\nsimple_cnn = models.resnet50(pretrained=True)\n#simple_cnn = models.resnet152(pretrained=True)\n#simple_cnn = models.alexnet(pretrained=True)\n#simple_cnn = models.vgg19_bn(pretrained=True)\nfor param in simple_cnn.parameters():\n    param.requires_grad = False\n#num_ftrs = simple_cnn.classifier[6].in_features\nnum_ftrs = simple_cnn.fc.in_features\nsimple_cnn.fc = nn.Linear(num_ftrs,n_classes)\n#simple_cnn.classifier[6] = nn.Linear(num_ftrs, n_classes)","metadata":{"id":"6tIEDzzxQQyt","outputId":"e97b00cd-4383-4536-d8db-39cd11c40839"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = len(np.unique(train_val_labels))\nsimple_cnn = SimpleCnn(n_classes).to(DEVICE)\n#simple_cnn = simple_cnn.to(DEVICE)\nprint(\"we will classify :{}\".format(n_classes))\nprint(simple_cnn)","metadata":{"id":"yzwhB4K3dQOC","outputId":"4b26c808-c8d4-4e10-d5ee-46b679aff83e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Запустим обучение сети.","metadata":{"id":"bo3UND5RdgVg"}},{"cell_type":"code","source":"if val_dataset is None:\n    val_dataset = SimpsonsDataset(val_files, mode='val')\n    \ntrain_dataset = SimpsonsDataset(train_files, mode='train')","metadata":{"id":"WDkcxZ1kfD4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train(train_dataset, val_dataset, model=simple_cnn, epochs=30, batch_size=256)","metadata":{"id":"iDXoR8PIdfLD","outputId":"3c89e17b-4a61-42fb-997c-3624c778357f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Построим кривые обучения","metadata":{"id":"7qMAdL_BduXZ"}},{"cell_type":"code","source":"torch.save(simple_cnn,'/content/gdrive/MyDrive/Kaggle_simpsons/res50.pth')\ntorch.save(simple_cnn.state_dict(), '/content/gdrive/MyDrive/Kaggle_simpsons/res501.pth')","metadata":{"id":"vRvHB4u7J1iQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!home","metadata":{"id":"GMG9crmpKS6e","outputId":"de703aa7-23ad-4e21-9f24-b86316e0d8f3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc, val_loss, val_acc = zip(*history)","metadata":{"id":"2ryD_9yFdfNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"id":"GpQDWGkfdfQ5","outputId":"e192309f-11c8-4df1-ce7d-08d7eb3e913e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ну и что теперь со всем этим делать?","metadata":{"id":"Gr9lRCJNNDfD"}},{"cell_type":"markdown","source":"![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)","metadata":{"id":"DSe0nQ-dJ8uy"}},{"cell_type":"markdown","source":"Хорошо бы понять, как сделать сабмит. \nУ нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим.","metadata":{"id":"y5k0UGeTNaQX"}},{"cell_type":"code","source":"def predict_one_sample(model, inputs, device=DEVICE):\n    \"\"\"Предсказание, для одной картинки\"\"\"\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"id":"Z8PlF6o0N9O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_characters = int(np.random.uniform(0,1000))\nex_img, true_label = val_dataset[random_characters]\nprobs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))","metadata":{"id":"pY_OoLoVO_9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = list(map(int, np.random.uniform(0,1000, 20)))\nimgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n\nprobs_ims = predict(simple_cnn, imgs)","metadata":{"id":"caivVFeAN9SY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"id":"t-0pRdHnQQKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(probs_ims,-1)\n\nactual_labels = [val_dataset[id][1] for id in idxs]\n\npreds_class = [label_encoder.classes_[i] for i in y_pred]","metadata":{"id":"GNMFc7sfQh1a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке.","metadata":{"id":"iVePL0-BKHrF"}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_score(actual_labels, y_pred, average='micro')\n","metadata":{"id":"_h-9dDWsKGU-","outputId":"f8afdcee-3f2a-4cbc-c3ea-d168cbc51b18"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода.","metadata":{"id":"pxB9pfPfdCHr"}},{"cell_type":"code","source":"import matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    \n    \n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n    \n    actual_text = \"Actual : {}\".format(img_label)\n            \n    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n    \n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n            \n    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')","metadata":{"id":"VVjq4EC5ZZE7","outputId":"5e66ea36-20d1-42c0-e324-8dc76fc32999"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tq3nMIqHeFFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем.","metadata":{"id":"hO9OLOMqIXRV"}},{"cell_type":"markdown","source":"### Submit на Kaggle","metadata":{"id":"QEWTL6jgdh7L"}},{"cell_type":"markdown","source":"![alt text](https://i.redd.it/nuaphfioz0211.jpg)","metadata":{"id":"wrjQ6cxHIGtk"}},{"cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(simple_cnn, test_loader)\n\n\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\ntest_filenames = [path.name for path in test_dataset.files]\n","metadata":{"id":"9UTbU0Zbc6Hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls ","metadata":{"id":"_rTtbV1teD2k","outputId":"525ef9d6-7d69-481c-b457-410cba2c1d29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmy_submit = pd.read_csv(\"/content/dataset/sample_submission.csv\")\nmy_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\nmy_submit.head()","metadata":{"id":"yw0zZ-Hdd89s","outputId":"28c6cb16-3436-48e9-f12c-4e51ffcc9acb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"id":"S_5Szl_1XHy9","outputId":"3e24e04f-fc25-4535-fe71-976a6be9f0df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO : сделайте сабмит (это важно, если Вы не справляетесь, но дошли до этой ячейки, то сообщите в чат и Вам помогут)","metadata":{"id":"VIYaqa20iYTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submit.to_csv('/content/dataset/simple_cnn_baseline_my.csv', index=False)","metadata":{"id":"5rdlyMKtiYe2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Приключение?\n\nА теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать. \n\nНесколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову: \n\n\n*   Учим дольше и изменяем гиперпараметры сети\n*  learning rate, batch size, нормализация картинки и вот это всё\n*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n\n* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n\n* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\n\n* Стоит подумать об ансамблях\n\n\nНадеюсь, что у Вас получится!\n\n![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\n","metadata":{"id":"h3M9SQZ7MuUq"}}]}